# Pre Work
#prework
## Chhapramhc44 Final Report
### Abstract
- BPTT - non-local, past signals
- RTRL (real-time recurrent learning) = BPTT, expensive computationally, non-local, no past signals
- Random-Feedback Local Online (RFLO) - approximation of RTRL using only local but can't learn complex tasks.

One feature of biological synapses that is missing in artificial neural nets is their internal dynamics over multiple timescales.
Investigate whether imbuing an RNNâ€™s connections with complex synapses can allow it to learn effectively in a self-organized way and based on information that is local to each synapse.

2 Approaches to model training - gradient based meta learning (well) and non-gradient optimisation (bad).

Gradient based meta learning
1) Network and synapses carried out in parallel - computationally prohibitive.
2) Supervised approach - learning symbols + gradients generated by BPTT - these for inputs and outputs for synapses to learn. - Very bad p: -0.1 (RCNN), 0.21 (RNN with RFLO), 0.98 (RNN - BPTT).

**Check best performance was actually -0.1**

### Introduction

BPTT = global information - weather prediction talk Richard turner? - Latent variables - O(N^2)
RTRL - forward pass BPTT - O(N^4) - local in time but not local in space (global variables)

Neural network weights are represented by a scalar value which is fixed once the network is fine-tuned to its training data.

Use a complex model of synapses (Benna and Fusi) where internal synaptic dynamics will receive local information and govern the learning of the network. 
Candidate learning signals ((Shervani-Tabar and Rosenbaum) and Murray) will output an update to RNN's weight.
One signal is global error signal (so non-local) argued by Lillicrap et al. - Suggests feedback connections may induce neural activity to approximate these signals.

**Check these papers**

### Background

#### Backpropagation through Time

Just normal equations - ignore.

#### Real-time Recurrent Learning

Summary of Murray paper

#### RFLO

![[Pasted image 20240915181258.png]]
RFLO good at small multiples of RNN time constant (**check this - probably a combination of the differential terms**).
Local is issue.
Random feedback - nearly as good as BPTT (also said by Lillicrap et al.).
#### Computational Principles of Synaptic Memory Consolidation, Benna and Fusi

Create synaptic model to preserve models from being overwritten.
Use multiple dynamic processes at different timescales.
Connections are bi-directional.
Synaptic modification, meta-plasticity and spacing effects emerge.

Simplest form - chain of dynamic variables where each variable only interacts with its neighbours in a differential equation.
Can control timescales.
Less `storages` = less memories but reducing `flow` between storages increase memory.

Once this chain model is generalised so arbitrary connections of the variables can be constructed, it is able to reproduce various experimental observations of biological memory systems.

Show model can model long term relationships while being resilient to short term noise.

#### Meta-learning Biologically Plausible Plasticity Rules, Shervani-Tabar and Rosenbaum
BPTT needs symmetric connectivity for propagation of gradient to earlier to time steps (or layers).
Called weight transport problem.
**Lillicrap et al.** (check out this - mentioned a lot but no meaning) shows that random backward connections can sufficiently transmit teaching signals - but deeper networks are harder (RNNS - can't train long sequences).
To solve - optimise parameters over local plasticity rules.
The goal is to develop general rules that are the same for all weights in the network rather than each weight having its own unique plasticity rule.
2 loops: Inner = weights, outer = meta rules.
Pool as good as BPTT but Feedback alignment (amit) is worse.
### Methods
#### Model Architecture
**Where did the RCN equation come from?**
Shared P parameters - the P parameters are the training. **Check the only thing being trained is the shared parameters - so every neural network connection is the same.**
Note the weights matrices are now updated at the end of every **image?** by the synapses and also that unlike the RNN states the RCNs retain their state information from sequence to sequence
z = number of parameters - **so what was the number of parameters used?**.
**What is equation 3.7 where is the weight matrix being used.**
RCNN = O(N^2$\times$P^2)
#### Meta-Learning Approaches
##### Supervised Meta-Learning of BPTT Gradients
RCN meant to model BPTT so train RNN normally and record learning signals from state information of RNN. Then use these states to train RCN.
**Double check learning signals are the values (vector) being sent down a `synapse`.**
Training cost lower.
##### Unsupervised Meta-Learning Using BPTT
The RCNs are tasked with implicitly determining the gradients for their corresponding RNN weights.
**Is algorithm 4 meant to say RCNN? - TBH what is going on here?**
Another issue encountered with this training method is that we would end up in local optima for parameters, the network would predict a uniform distribution for all classes in the case of discrete classification and for continuous function prediction tasks it would saturate the tanh function or predict a straight line.

**Question: As far as I can tell the meta learning approaches are trying to get the RCN to be in the same state at every node of the RNN. Why?**
#### Optimization
##### NGOpt by Meta
**Why is there no performance report on this?**
##### Evolutionary Strategies
Start with a set of parameters then either swap or add gaussian noise.
**Find some papers on this - pretty interesting.**
#### Discussion on Rationale and Biological Plausibility of Model
Probably read neuroscience book first.
#### Sequential Task Creation
##### EMNIST Dataset
Images - interesting - to do this without CNNs (which are probably more like the structure of neuron RFs in our eyes is very interesting).
Training on these tasks showed that the network would preferentially predict a uniform distribution, a very common local optimum likely due to the fact the network was being penalised for incorrect predictions early on despite not having sufficient information for correct classification - **I feel like this sentence doesn't make sense or why isn't this an issue in traditional RNNs**.
Why is predicting at every time step happening here though? Surely you can't do it until unravel entire image.
##### Gaussian Process Tasks
Fourier Series.
