@inproceedings{bengioGreedyLayerWiseTraining2006,
  title = {Greedy {{Layer-Wise Training}} of {{Deep Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
  date = {2006},
  volume = {19},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper_files/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html},
  urldate = {2024-10-10},
  abstract = {Recent analyses (Bengio, Delalleau, \& Le Roux, 2006; Bengio \& Le Cun, 2007) of modern nonparametric machine learning algorithms that are kernel machines, such as Support Vector Machines (SVMs), graph-based manifold and semi-supervised learning algorithms suggest fundamental limitations of some learning algorithms. The problem is clear in kernel-based approaches when the kernel is "local" (e.g., the Gaussian kernel), i.e., K (x, y ) converges to a constant when ||x - y || increases. These analyses point to the difficulty of learning "highly-varying functions", i.e., functions that have a large number of "variations" in the domain of interest, e.g., they would require a large number of pieces to be well represented by a piecewise-linear approximation. Since the number of pieces can be made to grow exponentially with the number of factors of variations in the input, this is connected with the well-known curse of dimensionality for classical non-parametric learning algorithms (for regression, classification and density estimation). If the shapes of all these pieces are unrelated, one needs enough examples for each piece in order to generalize properly. However, if these shapes are related and can be predicted from each other, "non-local" learning algorithms have the potential to generalize to pieces not covered by the training set. Such ability would seem necessary for learning in complex domains such as Artificial Intelligence tasks (e.g., related to vision, language, speech, robotics). Kernel machines (not only those with a local kernel) have a shallow architecture, i.e., only two levels of data-dependent computational elements. This is also true of feedforward neural networks with a single hidden layer (which can become SVMs when the number of hidden units becomes large (Bengio, Le Roux, Vincent, Delalleau, \& Marcotte, 2006)). A serious problem with shallow architectures is that they can be very inefficient in terms of the number of computational units (e.g., bases, hidden units), and thus in terms of required examples (Bengio \& Le Cun, 2007). One way to represent a highly-varying function compactly (with few parameters) is through the composition of many non-linearities, i.e., with a deep architecture. For example, the parity function with d inputs requires O(2d ) examples and parameters to be represented by a Gaussian SVM (Bengio et al., 2006), O(d2 ) parameters for a one-hidden-layer neural network, O(d) parameters and units for a multi-layer network with O(log2 d) layers, and O(1) parameters with a recurrent neural network. More generally,},
  file = {C:\Users\Kyle\Zotero\storage\RAEBBY6W\Bengio et al. - 2006 - Greedy Layer-Wise Training of Deep Networks.pdf}
}

@inproceedings{bengioLearningSynapticLearning1991,
  title = {Learning a Synaptic Learning Rule},
  booktitle = {{{IJCNN-91-Seattle International Joint Conference}} on {{Neural Networks}}},
  author = {Bengio, Y. and Bengio, S. and Cloutier, J.},
  date = {1991-07},
  volume = {ii},
  pages = {969 vol.2-},
  doi = {10.1109/IJCNN.1991.155621},
  url = {https://ieeexplore.ieee.org/document/155621},
  urldate = {2024-10-18},
  abstract = {Summary form only given, as follows. The authors discuss an original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible and yields networks that are able to learn to perform difficult tasks. The proposed method of automatically finding the learning rule relies on the idea of considering the synaptic modification rule as a parametric function. This function has local inputs and is the same in many neurons. The parameters that define this function can be estimated with known learning methods. For this optimization, particular attention is given to gradient descent and genetic algorithms. In both cases, estimation of this function consists of a joint global optimization of the synaptic modification function and the networks that are learning to perform some tasks. Both network architecture and the learning function can be designed within constraints derived from biological knowledge.{$<>$}},
  eventtitle = {{{IJCNN-91-Seattle International Joint Conference}} on {{Neural Networks}}},
  keywords = {Biological system modeling,Biology,Computer science,Genetic algorithms,Learning systems,Neurons},
  file = {C\:\\Users\\Kyle\\Zotero\\storage\\JZ6EYSBC\\Bengio et al. - 1991 - Learning a synaptic learning rule.pdf;C\:\\Users\\Kyle\\Zotero\\storage\\JLDA4IE5\\155621.html}
}

@inproceedings{bengioLearningSynapticLearning1991a,
  title = {Learning a Synaptic Learning Rule},
  booktitle = {{{IJCNN-91-Seattle International Joint Conference}} on {{Neural Networks}}},
  author = {Bengio, Y. and Bengio, S. and Cloutier, J.},
  date = {1991},
  pages = {969 vol.2},
  publisher = {IEEE},
  location = {Seattle, WA, USA},
  doi = {10.1109/IJCNN.1991.155621},
  url = {https://ieeexplore.ieee.org/document/155621/},
  urldate = {2024-10-18},
  abstract = {This paper presents an original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible, and yields networks that are able to learn to perform di cult tasks. The proposed method of automatically nding the learning rule relies on the idea of considering the synaptic modi cation rule as a parametric function. This function has local inputs and is the same in many neurons. The parameters that de ne this function can be estimated with known learning methods. For this optimization, we give particular attention to gradient descent and genetic algorithms. In both cases, estimation of this function consists of a joint global optimization of (a) the synaptic modi cation function, and (b) the networks that are learning to perform some tasks. The proposed methodology can be used as a tool to explore the missing pieces of the puzzle of neural networks learning. Both network architecture, and the learning function can be designed within constraints derived from biological knowledge.},
  eventtitle = {1991-{{Seattle International Joint Conference}} on {{Neural Networks}}},
  isbn = {978-0-7803-0164-1},
  langid = {english},
  file = {C:\Users\Kyle\Zotero\storage\AXCLBLYX\Bengio et al. - 1991 - Learning a synaptic learning rule.pdf}
}

@inproceedings{bengioUseGeneticProgramming1994,
  title = {Use of Genetic Programming for the Search of a New Learning Rule for Neural Networks},
  booktitle = {Proceedings of the {{First IEEE Conference}} on {{Evolutionary Computation}}. {{IEEE World Congress}} on {{Computational Intelligence}}},
  author = {Bengio, S. and Bengio, Y. and Cloutier, J.},
  date = {1994-06},
  pages = {324-327 vol.1},
  doi = {10.1109/ICEC.1994.349932},
  url = {https://ieeexplore.ieee.org/abstract/document/349932},
  urldate = {2024-10-17},
  abstract = {In previous work we explained how to use standard optimization methods such as simulated annealing, gradient descent and genetic algorithms to optimize a parametric function which could be used as a learning rule for neural networks. To use these methods, we had to choose a fixed number of parameters and a rigid form for the learning rule. In this article, we propose to use genetic programming to find not only the values of rule parameters but also the optimal number of parameters and the form of the rule. Experiments on classification tasks suggest genetic programming finds better learning rules than other optimization methods. Furthermore, the best rule found with genetic programming outperformed the well-known backpropagation algorithm for a given set of tasks.{$<>$}},
  eventtitle = {Proceedings of the {{First IEEE Conference}} on {{Evolutionary Computation}}. {{IEEE World Congress}} on {{Computational Intelligence}}},
  keywords = {Backpropagation algorithms,Biological system modeling,Design optimization,Genetic algorithms,Genetic programming,Learning systems,Neural networks,Neurons,Optimization methods,Simulated annealing},
  file = {C\:\\Users\\Kyle\\Zotero\\storage\\Y83VM8RA\\Bengio et al. - 1994 - Use of genetic programming for the search of a new learning rule for neural networks.pdf;C\:\\Users\\Kyle\\Zotero\\storage\\48L99IW7\\349932.html}
}

@article{bennaComputationalPrinciplesSynaptic2016,
  title = {Computational Principles of Synaptic Memory Consolidation},
  author = {Benna, Marcus K. and Fusi, Stefano},
  date = {2016-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {19},
  number = {12},
  pages = {1697--1706},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4401},
  url = {https://www.nature.com/articles/nn.4401},
  urldate = {2024-10-09},
  abstract = {The biological mechanisms underlying memory are complex and typically involve multiple molecular processes operating on timescales ranging from fractions of a second to years. The authors show using a mathematical model of synaptic plasticity and consolidation that this complexity can help explain the formidable memory capacity of biological systems.},
  langid = {english},
  keywords = {Consolidation,Long-term memory},
  file = {C:\Users\Kyle\Zotero\storage\DJIUDPI3\Benna and Fusi - 2016 - Computational principles of synaptic memory consolidation.pdf}
}

@book{dayanTheoreticalNeuroscienceComputational2001,
  title = {Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems},
  shorttitle = {Theoretical Neuroscience},
  author = {Dayan, Peter and Abbott, L. F.},
  date = {2001},
  series = {Computational Neuroscience},
  publisher = {Massachusetts Institute of Technology Press},
  location = {Cambridge, Mass},
  isbn = {978-0-262-04199-7},
  langid = {english},
  pagetotal = {460},
  file = {C:\Users\Kyle\Zotero\storage\S6TW4RBW\Dayan and Abbott - 2001 - Theoretical neuroscience computational and mathematical modeling of neural systems.pdf}
}

@article{metzMETALEARNINGUPDATERULES2019,
  title = {{{META-LEARNING UPDATE RULES FOR UNSUPER- VISED REPRESENTATION LEARNING}}},
  author = {Metz, Luke and Maheswaranathan, Niru and Cheung, Brian and Sohl-Dickstein, Jascha},
  date = {2019},
  abstract = {A major goal of unsupervised learning is to discover data representations that are useful for subsequent tasks, without access to supervised labels during training. Typically, this involves minimizing a surrogate objective, such as the negative log likelihood of a generative model, with the hope that representations useful for subsequent tasks will arise as a side effect. In this work, we propose instead to directly target later desired tasks by meta-learning an unsupervised learning rule which leads to representations useful for those tasks. Specifically, we target semi-supervised classification performance, and we meta-learn an algorithm –an unsupervised weight update rule – that produces representations useful for this task. Additionally, we constrain our unsupervised update rule to a be a biologically-motivated, neuron-local function, which enables it to generalize to different neural network architectures, datasets, and data modalities. We show that the meta-learned update rule produces useful features and sometimes outperforms existing unsupervised learning techniques. We further show that the meta-learned unsupervised update rule generalizes to train networks with different widths, depths, and nonlinearities. It also generalizes to train on data with randomly permuted input dimensions and even generalizes from image datasets to a text task.},
  langid = {english},
  file = {C:\Users\Kyle\Zotero\storage\L86ZJU64\Metz et al. - 2019 - META-LEARNING UPDATE RULES FOR UNSUPER- VISED REPRESENTATION LEARNING.pdf}
}

@article{shervani-tabarMetalearningBiologicallyPlausible2023,
  title = {Meta-Learning Biologically Plausible Plasticity Rules with Random Feedback Pathways},
  author = {Shervani-Tabar, Navid and Rosenbaum, Robert},
  date = {2023-03-31},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {1805},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37562-1},
  url = {https://www.nature.com/articles/s41467-023-37562-1},
  urldate = {2024-09-21},
  abstract = {Backpropagation is widely used to train artificial neural networks, but its relationship to synaptic plasticity in the brain is unknown. Some biological models of backpropagation rely on feedback projections that are symmetric with feedforward connections, but experiments do not corroborate the existence of such symmetric backward connectivity. Random feedback alignment offers an alternative model in which errors are propagated backward through fixed, random backward connections. This approach successfully trains shallow models, but learns slowly and does not perform well with deeper models or online learning. In this study, we develop a meta-learning approach to discover interpretable, biologically plausible plasticity rules that improve online learning performance with fixed random feedback connections. The resulting plasticity rules show improved online training of deep models in the low data regime. Our results highlight the potential of meta-learning to discover effective, interpretable learning rules satisfying biological constraints.},
  langid = {english},
  keywords = {Computational science,Learning algorithms},
  file = {C:\Users\Kyle\Zotero\storage\E6MFRN9F\Shervani-Tabar and Rosenbaum - 2023 - Meta-learning biologically plausible plasticity rules with random feedback pathways.pdf}
}
